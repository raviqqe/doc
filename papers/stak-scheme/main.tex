\documentclass[sigplan]{acmart}

\makeatletter
\if@ACM@review
\newcommand{\draft}[1]{CONTENT HIDDEN FOR REVIEWS}
\else
\newcommand{\draft}[1]{#1}
\fi
\makeatother

\acmConference[Scheme 2025]{Scheme Workshop in ICFP/SPLASH 2025}
\acmBooktitle{Presented at Scheme Workshop in ICFP/SPLASH 2025}
\settopmatter{printacmref=false, printccs=true}
\renewcommand\footnotetextcopyrightpermission[1]{}

\newcommand{\captionskip}{5pt}

\usepackage{algorithm2e}
\DontPrintSemicolon
\SetKwProg{Function}{function}{ do}{end}
\SetAlCapSkip{\captionskip}

\usepackage{caption}
\captionsetup{aboveskip=\captionskip, belowskip=\captionskip}

\usepackage{listings}
\lstdefinestyle{code}{basicstyle=\ttfamily\footnotesize}
\lstset{captionpos=b, style=code}

\keywords{Compiler, Virtual Machine, Dynamic Language, Scheme}

\begin{CCSXML}
  <ccs2012>
  <concept>
  <concept_id>10011007.10011006.10011008.10011009.10011012</concept_id>
  <concept_desc>Software and its engineering~Functional languages</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
  <concept>
  <concept_id>10011007.10011006.10011041.10010943</concept_id>
  <concept_desc>Software and its engineering~Interpreters</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
  % <concept>
  % <concept_id>10011007.10010940.10010971.10010564</concept_id>
  % <concept_desc>Software and its engineering~Embedded software</concept_desc>
  % <concept_significance>100</concept_significance>
  % </concept>
  </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~Functional languages}
\ccsdesc[500]{Software and its engineering~Interpreters}
% \ccsdesc[100]{Software and its engineering~Embedded software}

\begin{document}
\title{Stak Scheme: The tiny R7RS-small implementation}
\author{Yota Toyama}
\email{ytoyama42@gmail.com}

\begin{abstract}
  Small environments for embedded scripting allow software to
  evaluate logic dynamically on resource constrained platforms.
  In this paper, we present Stak Scheme, the tiny R7RS-small
  Scheme implementation.
  The whole interpreter of Stak Scheme contains no more than 10 KLOC as
  its core parts are composed of a bytecode compiler written in 1.6 KLOC
  of Scheme and a virtual machine written in 1.5 KLOC of Rust.
  Despite its minimal and naive design, Stak Scheme
  supports all major language features of the R7RS-small standard including
  but not limited to the library system, hygienic macros with
  \texttt{syntax-rules}, continuations, exception handling, and the
  fully-featured \texttt{eval} procedure.
  Our bytecode encoding and decoding algorithms convert code and
  data in bytecode uniformly
  between its in-memory graph format and serialized byte sequences.
  Our evaluation proves that the implementation of Stak Scheme is
  compact compared to the prior work of a small R7RS-small implementation
  whereas its performance is still comparable with other
  implementations of Scheme despite its minimal design.
\end{abstract}

\maketitle

\pagestyle{empty}

\section{Introduction}

In the Rust programming language as well as in other system
programming languages, it is cumbersome to evaluate programs
dynamically at runtime. At the same time, bundling large runtimes of
scripting languages into binaries is not always acceptable,
especially on resource constrained platforms, such as embedded systems.
On the other hand, Scheme and the other programming languages in the
Lisp family have widely
been used for such scripting purpose, such as Script-Fu \cite{scriptfu}
in GIMP, Guile \cite{guile} in several GNU applications, and
AutoLISP \cite{autolisp} in AutoCAD.

In this paper, we present Stak Scheme, the tiny R7RS-small Scheme
implementation\footnote{
  The implementation of Stak Scheme is available at
  \draft{\url{https://github.com/raviqqe/stak}}.
}.
Following the design of Ribbit Scheme
\cite{ribbit2023}, the tiny and
portable R4RS Scheme implementation, Stak Scheme's virtual machine
achieves reasonable performance and the minimal design
at the same time.
In addition, Stak Scheme supports platforms that do not provide
heap allocations or system APIs\footnote{
  These features correspond to the \texttt{alloc}
  crate (the heap allocation module) and the \texttt{std} crate (the
  system interface module) in Rust's standard library respectively.
}, which enables dynamic scripting in such constrained environments.

We make the following contributions in this paper:

\begin{itemize}
  \item We provide the smallest R7RS-small implementation ever in
    terms of its lines of code and binary size, which is implemented
    in Scheme and a system programming language.
    The core parts of the implementation are composed only of a 1.6 KLOC
    bytecode compiler in Scheme and a 1.5 KLOC virtual machine in Rust.
  \item We extend the Ribbit Virtual Machine (RVM) from the previous
    work of Ribbit Scheme to build an interpreter compatible with the
    R7RS-small standard on top of it.
    We prove that the architecture of RVM is scalable even when
    loaded with a large chunk of language features and standard
    libraries defined in the R7RS-small standard.
  \item We propose our simple bytecode encoding and decoding algorithms
    alternative to those used in Ribbit Scheme, which encode and
    decode both code and data uniformly and enable direct translation
    of symbols from different environments.
\end{itemize}

The main components of Stak Scheme are divided into two parts:
a bytecode compiler which compiles source code in Scheme into
bytecode (Section \ref{compiler}),
and a virtual machine which executes the compiled bytecode
(Section \ref{vm}).
In the compiler and the virtual machine, we introduce our simple
bytecode encoding and
decoding algorithms that convert code and data in bytecode
uniformly (Section \ref{bytecode}).
Another interesting trait of Stak Scheme is that the bytecode compiler itself
is an ingredient of the \texttt{(scheme eval)} library.
While compiling given source files, the compiler embeds itself
into the source files (Section \ref{inception}) to build up the library.
Finally, our evaluation demonstrates that the performance of Stak Scheme is
comparable with other Scheme implementations in spite of its minimal
design (Section \ref{evaluation}).

\section{Stak Scheme} \label{stak}

Stak Scheme is a tiny R7RS-small implementation consisting of a
bytecode compiler written in Scheme and a virtual machine written in Rust.
The bytecode compiler compiles Scheme source files and encodes their bytecode
into byte sequences.
The virtual machine decodes the serialized bytecode back into its
in-memory format and executes them.
This split architecture of a bytecode compiler and a virtual machine inherited
from Ribbit Scheme allows us to strip
out unnecessary logic from resulting binaries.
For example, we do not include the logic to parse S-expressions
in the virtual machine.
Instead, we compile and bundle the \texttt{read} procedure which parses
S-expressions in bytecode only if its source code imports the
\texttt{(scheme read)} standard library, which contains the
\texttt{read} procedure.
We discuss further details about the design and implementation of the
compiler and virtual machine in Section \ref{compiler} and Section
\ref{vm} respectively.

We design Stak Scheme for two use cases. One is to embed Scheme
programs as dynamic scripts inside Rust programs.
The other is to run standalone Scheme scripts on command lines directly.
For the former use case, we
compile Scheme scripts ahead into bytecode files and include them in
Rust programs via the Cargo build
system\footnote{\url{https://doc.rust-lang.org/cargo/}} so that the
Rust programs can execute them on the virtual machine at runtime.
For the latter use case, we
provide a standalone command named \texttt{stak} which runs Scheme script
files given as command line arguments.

Figure \ref{figure:build} shows an example workflow of
embedding a Stak Scheme script into a Rust program.
After a user triggers the \texttt{cargo build} command, which is of the
Cargo build system for Rust, a build
script invokes the \texttt{stak-compile} command of the Stak Scheme
bytecode compiler to compile a Scheme source file \texttt{foo.scm}
(List \ref{list:scheme}) into a bytecode file \texttt{foo.bc}
(List \ref{list:bytecode}).
After that, the Rust compiler \texttt{rustc} compiles a Rust source file
\texttt{main.rs} (List \ref{list:rust}) that includes the bytecode
file to produce a final executable file.

\begin{figure}
  \begin{center}
    \includegraphics[width=0.35\textwidth]{build.png}

    \caption{Workflow of embedding Stak Scheme in Rust}
    \label{figure:build}
  \end{center}
\end{figure}

\begin{lstlisting}[float, caption=\texttt{foo.scm} file, label=list:scheme]
(import (scheme base) (scheme write))

(define (fibonacci x)
  (if (< x 2)
    x
    (+
      (fibonacci (- x 1))
      (fibonacci (- x 2)))))

(write (fibonacci 32))
\end{lstlisting}

\begin{lstlisting}[float, caption=Disassembled \texttt{foo.bc} file, label=list:bytecode]
...
constant procedure 1 #f
  get 0
  constant 2
  call 2 #f $<
  if
    get 0
  get 0
  constant 1
  call 2 #f $-
  call 1 #f fibonacci
  get 1
  constant 2
  call 2 #f $-
  call 1 #f fibonacci
  call 2 #f $+
call 1 #f $$close
set fibonacci
constant 32
call 1 #f fibonacci
call 1 #f write
\end{lstlisting}

\begin{lstlisting}[float, caption=\texttt{main.rs} file, label=list:rust]
fn main() -> Result<(), Box<dyn Error>> {
  // Include and run a Scheme module.
  run_scheme(&include_module!("foo.scm"))?;

  Ok(())
}

fn run_scheme(module: &UniversalModule)
    -> Result<(), EngineError> {
  // Initialize a heap memory for an engine.
  let mut heap = [Default::default(); HEAP_SIZE];
  // Initialize the engine.
  let mut engine = Engine::new(&mut heap, &mut [])?;

  // Finally, run the Scheme module in the engine.
  engine.run(module)
}
\end{lstlisting}

\subsection{Compiler} \label{compiler}

The bytecode compiler of Stak Scheme compiles source files in Scheme
into bytecode.
The Scheme script of the compiler is compatible with any R7RS-small
implementations including Stak Scheme itself for the purpose of bootstrapping.
In the current implementation, a single Scheme file of 1.6 KLOC
contains the whole bytecode compiler.

The compiler is composed of the following stages.

\begin{enumerate}
  \item Source code parsing
  \item Compiler inception
  \item Library expansion
  \item Macro expansion
  \item Compilation
  \item Bytecode marshalling
  \item Bytecode encoding
\end{enumerate}

First, we parse source code as S-expressions from source
files skipping whitespace characters and comments.
Then, in the stage of compiler inception, we \textit{incept} the compiler
itself into the source code, which is described in details later in
Section \ref{inception}.
In library and macro expansions, we expand library and macro
syntaxes, such as \texttt{define-library}, \texttt{import},
\texttt{define-syntax}, and \texttt{syntax-rules} in the source code.
Following the specification of the library system in the R7RS-small
standard, we need to segregate environments of different libraries.
We represent such environments by creating symbols from
different environments with the non-standard
\texttt{string->uninterned-symbol} procedure.
If the procedure is not available in the compiler host, we emulate
the procedure by prepending unique prefixes to symbols' string
representations.
The hygienic macro system is the implementation of the
algorithm described in Macros That Work~\cite{macrosthatwork}.

The compilation phase compiles the expanded expressions to
bytecode in its in-memory format. Note that we use the same
in-memory format of the bytecode in our virtual machine as well.
Hence, we can reuse the compilation logic as it is
as well as the logic of library expansion and macro expansion inside
the \texttt{(scheme eval)} library.
We describe further details about how we reuse the compiler and build
the \texttt{(scheme eval)} library in Section \ref{inception}.

Before encoding the bytecode, we marshal them for the following purposes:

\begin{itemize}
  \item We marshal immediate values of certain data types in bytecode
    instructions into their serializable representations.
  \item We make boxed values of certain data types, such as strings and
    characters, unique in the bytecode so that we process them only once
    in the later bytecode encoding and reduce resulting bytecode sizes.
  \item We strip out string representation of symbols that are never used
    at runtime.
\end{itemize}

About the first item, to make the compiler compatible with any R7RS-small
implementations but not only Stak Scheme, we marshal immediate values
inside bytecode instructions into their ``universal"
representations compatible with any R7RS-small hosts that emulate
the data representations in our virtual machine
described later in Section \ref{vm}.
For example, we represent a string as a tuple of its length, a list of
character code points, and a tag for the string type in the compiler,
which is expressed as a pair of the length and the list
with a pointer tag on the \texttt{cdr} side in the virtual
machine of Stak Scheme.

Finally, the bytecode encoding phase encodes the in-memory representation of
bytecode into its serialized format and writes it into an output file.
We discuss the details of bytecode encoding in \ref{encoding}.

\subsection{Virtual machine} \label{vm}

Stak Scheme's virtual machine is designed after the one of Ribbit
Scheme, the Ribbit Virtual Machine (RVM).
Therefore, they share the large part of their design.
For example, both Ribbit and Stak Scheme's virtual machines represent
code and data as graphs of pair-like data structures in heap memory.
They initialize virtual machines by decoding bytecode onto
their heap memory.
However, we have several differences in instructions, Scheme value
representation, and bytecode.

First, while \texttt{constant}, \texttt{get}, \texttt{set}, and
\texttt{if} instructions in Stak Scheme are nearly identical to the ones in
Ribbit Scheme, the \texttt{call} instruction carries slightly
different semantics.
In Stak Scheme, the \texttt{call} instructions
contain function call signatures of an arity and
a flag indicating whether the function call is variadic or not.
This call signature is used to align argument and parameter counts and
resolve a \textit{rest} parameter comparing it with a signature of
the called procedure.
Thus, although Ribbit Scheme implements the \texttt{apply}
procedure as a virtual machine primitive, Stak Scheme does not have
such primitive but all the logic for the variadic argument handling
of the \texttt{apply} procedure resides in the \texttt{call} instruction.

Secondly, while Ribbit Scheme's virtual machine uses Ribs, triplets of
word-sized fields for internal representation of Scheme values, Stak
Scheme represents them as a traditional pair data structure of a
two-word size with optional tags attached to pointers in \texttt{cdr}.
This design choice simply saves a third of heap memory on the virtual machine
compared to Ribbit Scheme while it requires extra bit operations to
extract cons pointers and tags.
We use the optional pointer tags to encode instruction
codes or underlying data types primarily.
As well as Ribbit Scheme, we have only two primitive data types on virtual
machine; numbers and cons's.
A number is literally an internal representation of a mathematical number.
We currently provide three number
representations of 63-bit integers, 64-bit floating-point numbers,
and a mixture of 63-bit integers and 62-bit floating-point numbers
via Float Self-Tagging \cite{floatselftag}.
They are exclusive with each other and developers choose one
of the number representations when compiling the virtual machine.
A cons is a pair of two primitive values and represented as
a pointer into heap memory on the virtual machine.
In our Rust implementation of the virtual machine, we use an array of
primitive values as heap memory and indices into the array as cons
pointers.
In other implementations of the virtual machine, we can still fall
back to the data structures of Ribs where we allocate another
word-sized field for the tags if pointer tags are not available.

There is a subtle trick in our representation of Scheme values.
As we shrink down Ribs of triplets into traditional pairs, we sometimes
have no space to store data types as pointer tags anymore.
For example, how do we store the information that a value represented
by \texttt{(cons 1 2)} has the pair type?
The answer is that we assume tag values for numbers to be 0 which is of
the pair type
and store cons values in \texttt{cdr} for every other data type.
The internal representations of data types in Stak Scheme are listed
in Table \ref{table:types}.

\begin{table*}
  \begin{center}
    \begin{tabular}{lll}
      \hline
      Type & car & cdr \\
      \hline
      Pair & number or cons & number or cons \\
      Null & number & cons \\
      Boolean & number or cons & cons \\
      Procedure & cons (environment) & cons (signature and code) \\
      String & number (length) & cons (code points) \\
      Symbol & number or cons (value of global variable) & cons
      (string representation) \\
      Character & number (code point) & cons (null) \\
      Vector & number (length) & cons (elements) \\
      Bytevector & number (length) & cons (bytes) \\
      Record & cons (metadata) & cons (fields) \\
      \hline
    \end{tabular}

    \caption{Internal representation of Scheme values}
    \label{table:types}
  \end{center}
\end{table*}

Currently, we provide the implementation of the virtual machine only
in Rust.
However, as well as RVM, we believe that we can implement Stak Scheme's
virtual machine in different programming languages from low-level to high-level.
Besides, we do not assume linear memory on the virtual machine in such
host languages.
As such, developers can also utilize garbage collectors of
the host languages in implementations of the virtual machine if they want to.
We discuss this topic in Section \ref{portvm} as future work further.

In Section \ref{bytecode}, we describe the bytecode format for the
virtual machine and its encoding and decoding algorithms in details.

\subsection{Bytecode} \label{bytecode}

Stak Scheme's bytecode represents programs for the virtual machine to execute.
Following the bytecode design in Ribbit Scheme \cite{ribbit2023}, we pursue both
portability and compactness of the in-memory and on-disk bytecode
formats and the bytecode decoder that the virtual machine is
equipped with while keeping its computational performance.
Although we provide only the Rust implementation of the virtual machine,
we keep the serialized format of bytecode portable across
different implementations of the virtual machine in other host languages.
As such, we do not use, for example, snapshots of linear
memory of the virtual machine onto which we expand bytecode as a
serialization format of bytecode.

As described in Section \ref{vm},
we represent both code and data of instructions and immediate
values inside them in pair data structures consisting of two fields of
\texttt{car} and \texttt{cdr}.
Therefore, the problem of encoding and decoding bytecode falls into
the one on a graph of the pairs.
Furthermore, the graphs generated by the compiler are guaranteed to be
Directed Acyclic Graphs (DAGs), which even simplifies the encoding
and decoding algorithms.

In the following Section \ref{encoding} and Section \ref{decoding},
we describe details of bytecode encoding and decoding in Stak Scheme.
The key motivation to introduce our new encoding and decoding
algorithms different from the prior work of Ribbit Scheme is the differences
between the R4RS and R7RS-small standards, which Ribbit and Stak Scheme
support respectively.
First, the R7RS-small standard defines a larger set of standard
procedures and libraries, which makes resulting bytecode of Scheme
programs larger than the ones of R4RS.
Secondly, while the R4RS standard has only a single environment of
symbols for a Scheme program, the R7RS-small standard defines
separate environments for each library and a main program.

That being said, although Ribbit Scheme's bytecode encoding is very efficient
for small programs in R4RS Scheme already, Stak Scheme's encoding algorithm
deviates from it for two primary subjects.
First, the bytecode encoding in Ribbit Scheme requires a global symbol table.
Because this table is used for both global variables and as a cache of
boxed constant values, we suffer from the larger and larger global tables
as we grow the size of source programs and standard libraries.
When we self-host our fairly large bytecode compiler in Stak Scheme,
the performance degradation makes builds of Scheme programs painful due
to lengthy build times.
Therefore, our encoding algorithm in Stak Scheme takes another approach that
does not require any global symbol table.
Secondly, Ribbit Scheme's bytecode encoder encodes
immediate values of only primitive data types in bytecode instructions.
To encode complex data structures in the bytecode, the encoder
generates bytecode to initialize such values attached at the
beginning of the original programs.
In Stak Scheme, we instead encode instructions and their immediate
values in bytecode uniformly even when the immediate values are not
of primitive data types.
This approach also allows direct translation of symbols inside
different environments in bytecode from their in-memory format to
byte sequences in the compilation.
% Our preliminary experiments shows speedup of startup
% latencies of Scheme programs at the sacrifice of compact bytecode
% increasing their sizes in bytes.

\subsubsection{Encoding} \label{encoding}

We encode bytecode from its in-memory format into its serialized format in the
bytecode compiler.
We embed the serialized bytecode inside Rust programs for later
execution of them.
The serialized format of bytecode needs to be compact to save space in
resulting binaries, portable to be executable in different
implementations of the virtual machine, and performant so that we
decode them efficiently on the virtual machine.

For the bytecode encoding, we use an algorithm similar to topological
sort \cite{topologicalsort} with the following requirements.

\begin{itemize}
  \item We have different data types of immediate values in instructions,
    such as numbers, nulls, booleans, strings, symbols, and so on.
    Expectantly, we encode values of most of the data types without
    introducing ad-hoc encoding rules for each data type.
  \item We encode values that are unique, such as symbols, in
    bytecode only once
    because they should have (surprisingly) only one instance.
    We also uniquify values of several other boxed data
    types in a prior pass of bytecode marshalling in the
    compiler discussed in Section \ref{compiler}.
    We should not duplicate the continuations of \texttt{if}
    instructions either but encode them only once to avoid the exponential bloat
    of the serialized bytecode \cite{ribbit7kb2023}.
  \item We do not use any complex data structures but only singly-linked lists
    during encoding to keep the decoding algorithm simple by its using
    only primitive data structures of numbers and cons's available on
    the virtual machine.
\end{itemize}

Algorithm \ref{algorithm:encode} describes an overview of the bytecode
encoding.
The $encode$ function encodes a given value of
underlying bytecode recursively where $I$ is an input of in-memory
bytecode to encode,
$O$ is an output of serialized bytecode, $C$ is a precomputed map of
reference counts
at which times each cons appears in the bytecode and $D$ is a
dictionary of \textit{shared} cons's represented as a list.

For each given value, we check if the value is a cons or not.
If not, we encode it as a number.
Otherwise, we check if the cons already exists in the dictionary $D$ of
shared values.
If so, we remove the value from the dictionary and push the value to
the top of the dictionary unless its reference count is zero.
Then, we encode the value's index in the dictionary $D$ and a flag of whether it
is removed from the dictionary or not into the output via the
$encodeIndex$ function.
The operation to move the values to the top of the dictionary is based on the
assumption of reference locality of such shared values in bytecode.
If the value is not in the dictionary $D$, we encode the child values in
\texttt{car} and \texttt{cdr} recursively as well as its tag.
Then, if its reference count is not zero, we push the shared value to
the top of the dictionary because it is the first time for the shared value
to appear in the bytecode.
Across the function, we track how many times the cons's appear and
decrement their reference counts every time when they show up in the bytecode.
When the reference counts of cons's reach zero, they are removed from the
dictionary $D$ as described above.
The $encodeCons$, $encodeNumber$, $encodeIndex$, and $encodePush$
functions write their corresponding decode instructions as byte
sequences to the output $O$.

\begin{algorithm}
  \KwIn{In-memory bytecode $I$}
  \KwOut{Byte sequence $O$}

  \Function{encode(x, O)}{
    \uIf{cons?(x)}{
      $c \gets getCount(C, x)$ \;
      \uIf{contain?(D, x)}{
        $i \gets position(D, x)$ \;
        $C \gets decrement(C, x)$ \;
        $D \gets remove(D, i)$ \;
        \If{c \neq 0}{
          $D \gets push(D, x)$ \;
        }
        $encodeIndex(i, c = 0, O)$ \;
      }
      \Else{
        $encode(car(x), O)$ \;
        $encode(cdr(x), O)$ \;
        $encodeCons(tag(x), O)$ \;
        $C \gets decrement(C, x)$ \;
        \If{c > 0}{
          $D \gets push(D, x)$ \;
          $encodePush(O)$ \;
        }
      }
    }
    \Else{
      $encodeNumber(x, O)$ \;
    }
  }

  $encode(I, O)$ \;

  \caption{Bytecode encoding}
  \label{algorithm:encode}
\end{algorithm}

\subsubsection{Decoding} \label{decoding}

We decode the serialized form of bytecode into heap memory on
our virtual machine.
A chunk of bytecode for a Scheme program is a sequence of
variadic-length decode instructions of either $number$, $cons$, or $share$.
The bytecode decoding in Stak Scheme happens by looking at each
decode instruction in
the serialized bytecode from the beginning to the end.

Algorithm \ref{algorithm:decode} describes an overview of the
bytecode decoding.
We initialize $I$ of an input with bytecode and $S$ of a stack for decoded
values and $D$ of a dictionary with empty lists.
The decoding starts with looking at the first decode instruction in
the bytecode.
If it is a $number$ instruction, we decode and push a number onto the stack.
If it is a $cons$ instruction, we decode a tag and construct a cons
from \texttt{car} and \texttt{cdr} values popped from the stack
and the tag to push it onto the stack.
If it is a $share$ instruction and of a \textit{push} operation, we
copy and push the value at the top of a stack to the top of the dictionary.
Otherwise, we reference a shared value at its index in the
dictionary $D$ and push it onto the top of the stack.
Note that we also move the shared value to the top in the dictionary as well.
In addition, we remove the value from the dictionary if a flag $r$ is
true, which indicates that the value is not referenced anymore after the point.
Until we consume all the bytecode, we keep reading the decode instructions and
decode values.
Finally, the value at the top $car(S)$ is the root of the decoded
in-memory bytecode.

\begin{algorithm}
  \KwIn{Byte sequence $I$}
  \KwOut{In-memory bytecode $O$}

  $S \gets []$ \;
  $D \gets []$ \;
  \While{$I \neq []$}{
    $x \gets car(I)$ \;
    $I \gets cdr(I)$ \;
    \Switch{$instruction(x)$}{
      \uCase{$share$}{
        \uIf{$push?(x)$}{
          $D \gets cons(car(S), D)$ \;
        }
        \Else{
          $i, r, I \gets decodeIndex(x, I)$ \;
          \If{$i > 0$}{
            $d \gets tail(D, i - 1)$ \;
            $e \gets cdr(d)$ \;
            $cdr(d) \gets cdr(e)$ \;
            $D \gets cons(car(e), D)$ \;
          }
          $v \gets car(D)$ \;
          \If{$r$}{
            $D \gets cdr(D)$ \;
          }
          $S \gets cons(v, S)$ \;
        }
      }
      \uCase{$cons$}{
        $d \gets car(S)$ \;
        $S \gets cdr(S)$ \;
        $a \gets car(S)$ \;
        $S \gets cdr(S)$ \;
        $t, I \gets decodeCons(x, I)$ \;
        $S \gets cons(rib(a, d, t), S)$ \;
      }
      \Other{
        $n, I \gets decodeNumber(x, I)$ \;
        $S \gets cons(n, S)$ \;
      }
    }
  }

  $O \gets car(S)$ \;

  \caption{Bytecode decoding}
  \label{algorithm:decode}
\end{algorithm}

\subsection{Compiling the \texttt{eval} procedure} \label{inception}

The R7RS-small standard defines the \texttt{eval} procedure in the
\texttt{(scheme eval)} library, which evaluates arbitrary S-expressions in
arguments in specified evaluation environments.
In order to make the \texttt{eval} procedure fully-featured in Stak Scheme, we
ultimately need the full compiler we described in Section
\ref{compiler} inside the \texttt{(scheme eval)} library.

To realize that, we \textit{incept} the compiler itself into the
source code during the bytecode compilation.
In particular, the compiler script replaces
the \texttt{(\$\$compiler)} primitive call in the source code
with the compiler library right after the source code reading.
In the compiler script, we first define code of the compiler as
data stored in variables.
The compiler body is split into two parts.
The first part contains all the components required by the \texttt{eval}
procedure, such as the library system, the macro system, and the
bytecode compilation logic, that we embed into the source code.
The other half contains the other parts for the compiler, such
as bytecode marshalling and encoding logic.
In the main procedure of the compiler script, we combine the two
parts into one and apply the \texttt{eval} procedure against it to
run the whole compiler.

\subsection{Tree shaking}

One of methods to reduce the size of programs in dynamic programming
languages is tree shaking \cite{treeshaking}, which is commonly used
by optimizers and bundlers of JavaScript from Closure Compiler
\cite{closurecompiler}, to more recent ones, such as
Webpack \cite{webpack} and Rolldown \cite{rolldown}.
Tree shaking shakes down unnecessary code from a whole program
beyond its module boundaries with the analysis of symbol visibility
and side effects.
Although dead code elimination is a commonly known pass in the
compiler techniques, the term of tree shaking is used
in the context of dynamic programming languages where functions'
dependencies are not obvious statically.

Stak Scheme's bytecode compiler is equipped with a tree shaking pass.
It does not only reduce the size of bytecode but also
decreases the startup latencies because it reduces time spent for bytecode
decoding and program initialization on the virtual machine.
Since we expand libraries and macros statically
in our bytecode compiler, it is relatively simple to
implement tree shaking in Stak Scheme compared with other Scheme
implementations where, for example, the
\texttt{define-syntax} syntax is defined as a macro expanded at runtime.
We apply tree shaking only to the code of libraries but not main
programs because developers of main programs have full control over
them already; if tree shaking can reduce the size of the main programs,
that is the implication of unused procedures and variables, or
potentially bugs there.
Note that the tree shaking pass is disabled by default because we skew the
semantics of Scheme slightly to simplify its implementation.
For instance, when we define a variable with the \texttt{define} syntax and
specify its value of a procedure call expression
(e.g. \texttt{(define x (foo y))},) we remove the variable definition
whenever the defined variable is not used anywhere else even if the
procedure call causes side effects.

In addition, Stak Scheme also provides non-standard micro libraries
split out from the \texttt{(scheme base)} standard library under
the \texttt{stak} namespace.
Their names and functionalities are listed below.

\begin{description}
  \item[\texttt{(stak base)}] Arithmetic operations and basic types.
  \item[\texttt{(stak parameter)}] Parameter objects.
  \item[\texttt{(stak io)}] I/O operations and ports.
  \item[\texttt{(stak continue)}] Continuations and winding.
  \item[\texttt{(stak exception)}] Exception handling.
\end{description}

These micro libraries collectively provide the functionality of the entire
\texttt{(scheme base)} library.
They are especially useful on platforms where the size of bytecode
and/or startup latencies of the Scheme programs are critical.

\section{Evaluation} \label{evaluation}

Our evaluation of Stak Scheme demonstrates the minimality of its design and
implementation as well as its reasonable performance compared with
other Scheme implementations.

\subsection{Lines of code}

To evaluate the compactness of our implementation of Stak Scheme,
we compare lines of code between our Stak Scheme implementation and
another R7RS-small implementation, TR7 \cite{tr7}.
To the best of our knowledge, TR7 is the tiniest R7RS-small implementation
among the ones written in Scheme and a certain system programming language.

To count lines of code, we exclude test code, comments, and blank
lines from source code in each implementation.
For Stak Scheme, there is no test code written in Scheme but only in Rust.
In the Rust code, we removed modules that are compiled only for tests.
In TR7, because it separates test code into different files, we simply did not
include such files.
Besides, we apply code formatters of \texttt{rustfmt} (v1.8.0),
\texttt{clang-format} (v20.1.7), and \texttt{schemat} (v0.4.1) for
Rust, C, and Scheme files respectively for the consistent format of
the source code.

As Table \ref{table:loc} shows, Stak Scheme almost
halves the code size compared to TR7.
One of the key factors is its split architecture of the bytecode
compiler in Scheme and the virtual machine in Rust.
As a result, we can write the large part of the language processor in Scheme
itself that is more abstract and high-level than Rust or C.
The small virtual machine design borrowed from Ribbit Scheme also
contributes to reduce the code size of its implementation in Rust.

\begin{table}
  \begin{center}
    \begin{tabular}{l|rrrrrrrr}
      \hline
      Language & Stak & TR7  \\
      \hline
      Scheme & 4,952 & 116 \\
      C / Rust & 4,175 & 16,775 \\
      Total & 9,127 & 16,891 \\
      \hline
    \end{tabular}

    \caption{Lines of code}
    \label{table:loc}
  \end{center}
\end{table}

Although both Stak Scheme and TR7 do not implement the complete
specification of the R7RS-small standard, we believe that the other
implementations would not be comparable with them since
they implement all the primary language features,
such as library system and hygienic macros, already.
The current implementation of Stak Scheme lacks only precise
implementation of the \texttt{include} and \texttt{include-ci} syntaxes.
As adding missing functions or syntaxes are trivial changes,
implementing such additional functionalities would not change the
order of their lines of code.

\subsection{Binary sizes}

As well as lines of code, we compare binary sizes of executable files of
interpreters among Stak Scheme and the other Scheme implementations
to evaluate their compactness.
We compile these executable files for the x86-64 CPU architecture on
the operating system of Ubuntu 24.04.
For the comparison, we pick the default version of Stak Scheme (\texttt{stak})
that uses a mixture of 63-bit integers and 62-bit floating-point
numbers with Float Self-Tagging \cite{floatselftag} as its number
representation for the sake of the better feature parity with
the other Scheme implementations while Stak Scheme does not implement
the full numeric tower defined in the R7RS-small standard unlike others.
That version of Stak Scheme comes with its R7RS standard libraries built on
the standard libraries of Rust.
We also compare \texttt{mstak} as a baseline, which comes with a number
representation of only 63-bit integers and its standard libraries backed
by the C standard libraries.
For a reference, we compare \texttt{chibi-scheme-static}, which is an
executable file of the Chibi Scheme interpreter compiled with its library linked
statically and C compiler flags of \texttt{SEXP\_USE\_NO\_FEATURES=1} and
\texttt{SEXP\_USE\_FLONUMS=1} to minimize its binary size.
We strip debug information from these executable files because
our focus is the size comparison of the interpreter logic itself.

Table \ref{table:binary} shows the sizes of the executable files.
The numbers are without the sizes of dynamic libraries common across
all the executable files.
As you see in the table, the binary size of \texttt{mstak} is almost
a third of \texttt{tr7i}.
On the other hand, \texttt{stak} is far larger than \texttt{mstak} and
\texttt{tr7i} due to the bulky Rust libraries.
Chibi Scheme shows the binary size a few times larger than \texttt{mstak} or
\texttt{tr7i}.

While Ribbit Scheme \cite{ribbit7kb2023} achieves its 7 KB binary size
of a REPL executable file implementing the full R4RS standard, Stak
Scheme weighs 109 KB.
Even when we consider the size of the R7RS-small standard, this is
exceedingly large compared to Ribbit Scheme.
The total binary size of Stak Scheme consists of 46 KB bytecode and
the other part of 63 KB, such as machine code.
The large bytecode size is partially due to a lack of
bytecode size optimization from Stak Scheme which Ribbit Scheme already
implements, such as RIBN's \texttt{optimal} encoding and the
LZSS compression.
Another reason for the large bytecode size is our full-fledged
\texttt{eval} procedure in the interpreter, which contains the
whole bytecode compiler.
For the non-bytecode part, we do not implement our VM in x86-64
assembly like Ribbit Scheme and we implement our R7RS standard libraries
based upon and linked with the C standard library,
which contributes to the size bloat of the machine code.
Although we can technically implement another interpreter
(e.g. AST-based) in Scheme itself which does not integrate the
existing Scheme-to-bytecode compiler as well as Ribbit Scheme,
we do not concerning the potential degradation of
computational performance and the maintenance cost of keeping two
language processors in the single Scheme implementation.

\begin{table}
  \begin{center}
    \begin{tabular}{l|r}
      \hline
      Interpreter & Size / bytes \\
      \hline
      mstak & 108,648 \\
      stak & 770,720 \\
      tr7i & 301,536 \\
      chibi-scheme-static & 1,094,664 \\
      \hline
    \end{tabular}

    \caption{Binary sizes}
    \label{table:binary}
  \end{center}
\end{table}

\subsection{Computational benchmarks}

We compare interpreters of Stak Scheme and other Scheme
implementations compliant with the R7RS-small standard in computational
benchmarks shown in Table \ref{table:computation}.
The following benchmarks are used to evaluate the Scheme interpreters.
In addition to typical microbenchmarks of \textbf{fibonacci},
\textbf{sum}, and \textbf{tak} for pure computations, we add
\textbf{empty} and \textbf{hello} in order to assess the
lightweightness of the interpreters.
We run each benchmark 10 times with 5 warm-up runs and report the
average execution time as well as the standard deviation.

\begin{description}
  \item[empty] runs no code (an empty script.)
  \item[fibonacci] calculates a Fibonacci number.
  \item[hello] prints a string of ``Hello, world!"
  \item[sum] sums integers.
  \item[tak] calculates a value of the Tak function.
\end{description}

The following list is the versions and the implementations of
Scheme interpreters compared in the benchmarks.
For Stak Scheme, we run the benchmarks against its bytecode interpreters as well
which run bytecode pre-compiled from Scheme source code directly
emulating situations of embedded scripting described in Section \ref{stak}.

\begin{description}
  \item[mstak] Stak Scheme 0.10.38 (63-bit integer only, libc)
  \item[stak] Stak Scheme 0.10.38 (64-bit floating point number support, the
    \texttt{std} library in Rust)
  \item[mstak bc] The bytecode interpreter for \texttt{mstak}
  \item[stak bc] The bytecode interpreter for \texttt{stak}
  \item[tr7i] The TR7 interpreter at the commit \texttt{e821e555}
    on the \texttt{v2} branch
  \item[gsi] The interpreter of Gambit Scheme 4.9.7
  \item[chibi-scheme] Chibi Scheme 0.11
  \item[gosh] Gauche 0.9.15
\end{description}

The interpreters listed above are not equipped with any JIT compilation
or other methods compiling the languages into native code.
They are rather AST-based or bytecode-based interpreters.
We run our benchmarks on a MacBook Air with macOS Sequoia 15.5 and an Apple
M2 CPU with the 64-bit ARM architecture.

The results in Table \ref{table:computation} indicate that Stak
Scheme's computational performance remains comparable with other
Scheme implementations with performance, for instance, 1.67 times
faster than \textbf{gsi} in the \textbf{fibonacci} benchmark,
despite its minimal design and implementation.
In contrast, it suffers on the \textbf{sum} benchmark against
\textbf{gosh} as Stak Scheme is not
particularly optimized for but uses tail calls for iterations,
In the benchmarks of \textbf{empty} and \textbf{hello}, our interpreters,
especially its bytecode interpreters, perform significantly better
than the other Scheme implementations.
This does not only highlight the lightweight nature of the Stak Scheme
implementation, but also demonstrates that
the split architecture of a bytecode compiler and a virtual machine,
as exemplified by both Stak Scheme and Ribbit Scheme is well-suited for
embedded scripting.

\begin{table*}
  \begin{center}
    \begin{tabular}{l|llllllllllllllllll}
      \hline
      Benchmark & mstak & stak & mstak bc & stak bc &
      gsi & chibi-scheme & gosh \\
      \hline
      empty & 1.00 \pm 0.02 & 1.04 \pm 0.02 & 0.13 \pm 0.00 & 0.37
      \pm 0.01 & 0.46 \pm 0.02 & 3.70 \pm 0.03 & 1.25 \pm 0.04 \\
      fibonacci & 1.00 \pm 0.00 & 1.12 \pm 0.00 & 0.99 \pm 0.00 &
      1.06 \pm 0.00 & 1.65 \pm 0.00 & 0.92 \pm 0.00 & 0.39 \pm 0.01 \\
      hello & 1.00 \pm 0.01 & 1.06 \pm 0.02 & 0.14 \pm 0.01 & 0.37
      \pm 0.01 & 0.50 \pm 0.01 & 9.96 \pm 0.06 & 3.55 \pm 0.05 \\
      sum & 1.00 \pm 0.00 & 1.12 \pm 0.00 & 1.14 \pm 0.02 & 1.06 \pm
      0.00 & 1.63 \pm 0.00 & 0.97 \pm 0.00 & 0.23 \pm 0.00 \\
      tak & 1.00 \pm 0.01 & 1.08 \pm 0.01 & 0.94 \pm 0.01 & 0.98 \pm
      0.01 & 1.21 \pm 0.01 & 1.21 \pm 0.01 & 0.48 \pm 0.00 \\
      \hline
    \end{tabular}

    \caption{Computational benchmarks (relative time. lower is better.)}
    \label{table:computation}
  \end{center}
\end{table*}

\section{Related work}

Ribbit Scheme \cite{ribbit2023} is the tiny and portable R4RS Scheme
implementation we designed Stak Scheme after. They provide
the Ribbit Virtual Machines (RVMs) implemented in various
programming languages
including x86-64 assembly, C, JavaScript, Bash, Scheme, etc.
They have first coined the basic architecture of Ribbit Scheme
\cite{ribbit2021} where its implementation is composed of an
Ahead-Of-Time (AOT) bytecode compiler and a tiny virtual machine.
The AOT compiler compiles source code in Scheme and produces
an executable binary bundled with a virtual machine of a specified backend.
This architecture allows users to strip unnecessary language
features and minimize resulting binaries.
In RVM, every code or data is represented in
Ribs, which are tuples of three fields.
That does not only make the implementation of
RVMs simple but make them portable across different
programming languages from low-level to high-level.

TR7 \cite{tr7} is the tiny R7RS Scheme implementation written in C.
The key differences between Stak Scheme and TR7 are primary languages used in
the implementation and how they strip out features from the
interpreters.
TR7 intentionally uses only C for most part of its implementation and
contains its entire interpreter in one \texttt{tr7.c} source file and a
\texttt{tr7.h} header file whereas Stak Scheme uses both Scheme and
Rust for its bytecode compiler and virtual machine.
TR7 allows users to strip language features from the interpreter via
the C preprocessor flags prefixed with \texttt{USE\_}.
On the other hand, Stak Scheme allows users to strip out the majority of
the interpreter logic, such as S-expression parsing, library system, and
macro expansion, from resulting binaries in its bytecode compiler
depending of libraries that given source programs import.

While there are many methods to implement Scheme, all Ribbit Scheme,
TR7, and Stak Scheme adopt bytecode virtual machines for their
compact implementations.
Although Scheme-to-C compilers, such as the Gambit Scheme compiler and
Chicken Scheme, allow code generation portable to many platforms
thanks to C compilers, they usually come with certain forms of embedded
interpreters for implementation of the \texttt{eval} procedure.
Thus, Scheme-to-C compilers are not the optimal approach for minimal
R7RS-small Scheme implementations due to the duplication of logic between the
compiler and the interpreter.
Native Scheme compilers like Chez Scheme is also another approach to
implement Scheme which generates native code directly from Scheme source code.
Although native code compilers generate well-optimized code, such
compilers tend to be large in terms of lines of code.
As such, we did not take the approach for Stak Scheme either.

\section{Future work}

\subsection{Type checking and virtual machine memory safety}

One of the reasons why Stak Scheme is tiny and its performance is still
comparable with the other Scheme implementations is that its
programs are not memory safe on the virtual machine even though
the host language is memory safe.
In other words, programs written in Stak Scheme are able to access any memory
locations on the virtual machine as long as the host languages allow that.
In the virtual machine we implemented in Rust, this memory
unsafety on the virtual machine sometimes arises as panics with little
contextual information.
Such panics are hard to debug, especially when debug information is
stripped out from executable files of the interpreter.
We have a plan to implement basic type checks in our virtual machine
in the host language of Rust in order to enhance memory safety on
the virtual machine without sacrificing its performance.

\subsection{Porting virtual machines to other languages} \label{portvm}

Although we believe that our bytecode decoding algorithm work
universally across different host languages, we did not implement them in
virtual machines written in programming languages other than Rust yet.
For the first step, we have a plan to implement another virtual
machine in the Go programming language, which is another memory-safe system
programming language widely used today.
As Go comes with its own garbage collector,
it would be intriguing to evaluate how well its implementation of the
virtual machine performs compared with the virtual
machine with copy garbage collection in Rust.
Porting the Stak Scheme virtual machine to other languages does
not only prove its portability but also extends its use cases.

\section{Conclusion}

Stak Scheme is a tiny R7RS-small implementation written in Scheme and
Rust.
Although our implementation of Stak Scheme is minimal in terms of
lines of code and binary size, it still demonstrates reasonable performance.
Our evaluation shows that Stak Scheme is
comparable with the other Scheme implementations in terms of
computational performance.

We plan to further improve the design and implementation of Stak
Scheme in the future. The upcoming work includes but is not limited
to type checking and porting the virtual machine to
another system programming language.

\begin{acks}
  We cannot thank enough the dynamic programming language team at the
  University of Montréal, Canada for the foundational work of Ribbit
  Scheme, which heavily inspired the design and implementation of
  Stak Scheme.
  I would also like to express my appreciation to all pre-submission
  reviewers for their feedback on this paper.
  Léonard Oest O'Leary from the team in the University of Montréal provided
  valuable comments including suggestions for improving the
  evaluation sections.
  William E. Byrd gave us general advice on academic writing and put
  many helpful comments on the original draft.
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
